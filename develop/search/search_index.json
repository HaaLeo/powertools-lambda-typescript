{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"A suite of utilities for AWS Lambda functions to ease adopting best practices such as tracing, structured logging, custom metrics, and more. Looking for a quick read through how the core features are used? Check out this detailed blog post with a practical example. Tenets \u00b6 This project separates core utilities that will be available in other runtimes vs general utilities that might not be available across all runtimes. AWS Lambda only . We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported. Eases the adoption of best practices . The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional. Keep it lean . Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time. We strive for backwards compatibility . New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined. We work backwards from the community . We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs) Progressive . Utilities are designed to be incrementally adoptable for customers at any stage of their Serverless journey. They follow language idioms and their community\u2019s common practices. Install \u00b6 Features \u00b6 Utility Description Tracer Decorators and utilities to trace Lambda function handlers, and both synchronous and asynchronous functions Logger Structured logging made easier, and decorator to enrich structured logging with key Lambda context details Metrics Custom Metrics created asynchronously via CloudWatch Embedded Metric Format (EMF) Environment variables \u00b6 Info Explicit parameters take precedence over environment variables. Environment variable Description Utility Default POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All \"service_undefined\" POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics None POWERTOOLS_TRACE_DISABLED Explicitly disables tracing Tracing false POWERTOOLS_TRACER_CAPTURE_RESPONSE Captures Lambda or method return as metadata. Tracing true POWERTOOLS_TRACER_CAPTURE_ERROR Captures Lambda or method exception as metadata. Tracing true POWERTOOLS_LOGGER_LOG_EVENT Logs incoming event Logging false POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging 0 POWERTOOLS_LOG_DEDUPLICATION_DISABLED Disables log deduplication filter protection to use Pytest Live Log feature Logging false LOG_LEVEL Sets logging level Logging INFO","title":"Homepage"},{"location":"#tenets","text":"This project separates core utilities that will be available in other runtimes vs general utilities that might not be available across all runtimes. AWS Lambda only . We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported. Eases the adoption of best practices . The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional. Keep it lean . Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time. We strive for backwards compatibility . New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined. We work backwards from the community . We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs) Progressive . Utilities are designed to be incrementally adoptable for customers at any stage of their Serverless journey. They follow language idioms and their community\u2019s common practices.","title":"Tenets"},{"location":"#install","text":"","title":"Install"},{"location":"#features","text":"Utility Description Tracer Decorators and utilities to trace Lambda function handlers, and both synchronous and asynchronous functions Logger Structured logging made easier, and decorator to enrich structured logging with key Lambda context details Metrics Custom Metrics created asynchronously via CloudWatch Embedded Metric Format (EMF)","title":"Features"},{"location":"#environment-variables","text":"Info Explicit parameters take precedence over environment variables. Environment variable Description Utility Default POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All \"service_undefined\" POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics None POWERTOOLS_TRACE_DISABLED Explicitly disables tracing Tracing false POWERTOOLS_TRACER_CAPTURE_RESPONSE Captures Lambda or method return as metadata. Tracing true POWERTOOLS_TRACER_CAPTURE_ERROR Captures Lambda or method exception as metadata. Tracing true POWERTOOLS_LOGGER_LOG_EVENT Logs incoming event Logging false POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging 0 POWERTOOLS_LOG_DEDUPLICATION_DISABLED Disables log deduplication filter protection to use Pytest Live Log feature Logging false LOG_LEVEL Sets logging level Logging INFO","title":"Environment variables"},{"location":"changelog/","text":"Change Log \u00b6 All notable changes to this project will be documented in this file. See Conventional Commits for commit guidelines. 0.2.0-beta.5 (2021-12-21) \u00b6 Note: Version bump only for package aws-lambda-powertools-typescript 0.2.0-beta.4 (2021-12-21) \u00b6 Note: Version bump only for package aws-lambda-powertools-typescript 0.2.0-beta.3 (2021-12-17) \u00b6 Note: Version bump only for package aws-lambda-powertools-typescript 0.2.0-beta.2 (2021-12-17) \u00b6 Note: Version bump only for package aws-lambda-powertools-typescript 0.2.0-beta.1 (2021-12-17) \u00b6 Note: Version bump only for package aws-lambda-powertools-typescript 0.2.0-beta.0 (2021-12-17) \u00b6 Features \u00b6 tracer: middy middleware ( #324 ) ( 2909d6f ) 0.1.0-beta.9 (2021-12-15) \u00b6 Bug Fixes \u00b6 metrics: lib entrypoint ( 819098b ) 0.1.0-beta.8 (2021-12-15) \u00b6 Note: Version bump only for package aws-lambda-powertools-typescript 0.1.0-beta.7 (2021-12-15) \u00b6 Bug Fixes \u00b6 cicd: Fix/release ( #323 ) ( 9df4493 ) ci: merge conflict ( 97796df ) ci: updated github actions commands ( 76ba8c7 ) ci: updated NPM dependencies (audit) ( 3166c7b ) hosted-git-info bump in logger ( fb2a365 ) logger: jest set to next version as workaround for vulnerability ( 0f423bf ) logging: removed forgotten dummy folder ( a10791f ) metrics: publish metrics even if handler throw ( #249 ) ( 8ad0a6a ) upgrade of dependencies, npm-shrinkwrap for packages/logger ( c120c64 ) version bumb for commitlint/cli ( 0e1f6be ) Features \u00b6 add metrics ( #102 ) ( cf22210 ) Adding sample automation for PR ( #121 ) ( 7bf63bb ) logger: add context decorator functionality ( #13 ) ( 369e4d1 ) logger: adding basic crude logger module, and support for log levels by passed param/env param ( a3ff0ba ) logger: basic logger logic ( #9 ) ( 5f867ea ), closes #10 logger: lint error fixes ( 5272ac0 ) logging: added basic lerna package for the logging module ( 14c679d ) Changelog \u00b6 All notable changes to this project will be documented in this file. This project follows Keep a Changelog format for changes and adheres to Semantic Versioning . [Unreleased] \u00b6 0.1.0 \u00b6 Features \u00b6 tracer: beta release ( #91 ) logger: beta release ( #24 ) metrics: beta release ( #25 )","title":"Changelog"},{"location":"changelog/#change-log","text":"All notable changes to this project will be documented in this file. See Conventional Commits for commit guidelines.","title":"Change Log"},{"location":"changelog/#020-beta5-2021-12-21","text":"Note: Version bump only for package aws-lambda-powertools-typescript","title":"0.2.0-beta.5 (2021-12-21)"},{"location":"changelog/#020-beta4-2021-12-21","text":"Note: Version bump only for package aws-lambda-powertools-typescript","title":"0.2.0-beta.4 (2021-12-21)"},{"location":"changelog/#020-beta3-2021-12-17","text":"Note: Version bump only for package aws-lambda-powertools-typescript","title":"0.2.0-beta.3 (2021-12-17)"},{"location":"changelog/#020-beta2-2021-12-17","text":"Note: Version bump only for package aws-lambda-powertools-typescript","title":"0.2.0-beta.2 (2021-12-17)"},{"location":"changelog/#020-beta1-2021-12-17","text":"Note: Version bump only for package aws-lambda-powertools-typescript","title":"0.2.0-beta.1 (2021-12-17)"},{"location":"changelog/#020-beta0-2021-12-17","text":"","title":"0.2.0-beta.0 (2021-12-17)"},{"location":"changelog/#features","text":"tracer: middy middleware ( #324 ) ( 2909d6f )","title":"Features"},{"location":"changelog/#010-beta9-2021-12-15","text":"","title":"0.1.0-beta.9 (2021-12-15)"},{"location":"changelog/#bug-fixes","text":"metrics: lib entrypoint ( 819098b )","title":"Bug Fixes"},{"location":"changelog/#010-beta8-2021-12-15","text":"Note: Version bump only for package aws-lambda-powertools-typescript","title":"0.1.0-beta.8 (2021-12-15)"},{"location":"changelog/#010-beta7-2021-12-15","text":"","title":"0.1.0-beta.7 (2021-12-15)"},{"location":"changelog/#bug-fixes_1","text":"cicd: Fix/release ( #323 ) ( 9df4493 ) ci: merge conflict ( 97796df ) ci: updated github actions commands ( 76ba8c7 ) ci: updated NPM dependencies (audit) ( 3166c7b ) hosted-git-info bump in logger ( fb2a365 ) logger: jest set to next version as workaround for vulnerability ( 0f423bf ) logging: removed forgotten dummy folder ( a10791f ) metrics: publish metrics even if handler throw ( #249 ) ( 8ad0a6a ) upgrade of dependencies, npm-shrinkwrap for packages/logger ( c120c64 ) version bumb for commitlint/cli ( 0e1f6be )","title":"Bug Fixes"},{"location":"changelog/#features_1","text":"add metrics ( #102 ) ( cf22210 ) Adding sample automation for PR ( #121 ) ( 7bf63bb ) logger: add context decorator functionality ( #13 ) ( 369e4d1 ) logger: adding basic crude logger module, and support for log levels by passed param/env param ( a3ff0ba ) logger: basic logger logic ( #9 ) ( 5f867ea ), closes #10 logger: lint error fixes ( 5272ac0 ) logging: added basic lerna package for the logging module ( 14c679d )","title":"Features"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. This project follows Keep a Changelog format for changes and adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#unreleased","text":"","title":"[Unreleased]"},{"location":"changelog/#010","text":"","title":"0.1.0"},{"location":"changelog/#features_2","text":"tracer: beta release ( #91 ) logger: beta release ( #24 ) metrics: beta release ( #25 )","title":"Features"},{"location":"core/logger/","text":"Logger provides an opinionated logger with output structured as JSON. Key features \u00b6 Capture key fields from Lambda context, cold start and structures logging output as JSON Log Lambda context when instructed (disabled by default) Log sampling prints all logs for a percentage of invocations (disabled by default) Append additional keys to structured log at any point in time Getting started \u00b6 Logger requires two settings: Setting Description Environment variable Constructor parameter Logging level Sets how verbose Logger should be (INFO, by default) LOG_LEVEL logLevel Service name Sets the name of service of which the Lambda function is part of, that will be present across all log statements POWERTOOLS_SERVICE_NAME serviceName Example using AWS Serverless Application Model (SAM) handler.ts template.yaml 1 2 3 4 5 6 7 8 9 10 import { Logger } from \"@aws-lambda-powertools/logger\" ; // Logger parameters fetched from the environment variables (see template.yaml tab) const logger = new Logger (); // You can also pass the parameters in the constructor // const logger = new Logger({ // logLevel: \"INFO\", // serviceName: \"shopping-cart-api\" // }); 1 2 3 4 5 6 7 8 9 Resources : ShoppingCartApiFunction : Type : AWS::Serverless::Function Properties : Runtime : nodejs14.x Environment : Variables : LOG_LEVEL : INFO POWERTOOLS_SERVICE_NAME : shopping-cart-api Standard structured keys \u00b6 Your Logger will include the following keys to your structured logging (default log formatter): Key Example Note level : string INFO Logging level set for the Lambda function\"s invocation message : string Query performed to DynamoDB A descriptive, human-readable representation of this log item sampling_rate : float 0.1 When enabled, it prints all the logs of a percentage of invocations, e.g. 10% service : string shopping-cart-api A unique name identifier of the service this Lambda function belongs to, by default service_undefined timestamp : string 2011-10-05T14:48:00.000Z Timestamp string in simplified extended ISO format (ISO 8601) xray_trace_id : string 1-5759e988-bd862e3fe1be46a994272793 When tracing is enabled , it shows X-Ray Trace ID error : Object { name: \"Error\", location: \"/my-project/handler.ts:18\", message: \"Unexpected error #1\", stack: \"[stacktrace]\"} Optional - An object containing information about the Error passed to the logger Capturing Lambda context info \u00b6 You can enrich your structured logs with key Lambda context information in multiple ways. Method 1, using a Middy middleware: handler.ts 1 2 3 4 5 6 7 8 9 10 11 import { Logger , injectLambdaContext } from \"@aws-lambda-powertools/logger\" ; import middy from '@middy/core' ; const logger = new Logger (); const lambdaHandler = async () => { logger . info ( \"This is an INFO log with some context\" ); }; const handler = middy ( lambdaHandler ) . use ( injectLambdaContext ( logger )); Method 2, calling the addContext method: handler.ts 1 2 3 4 5 6 7 8 9 10 11 import { Logger } from \"@aws-lambda-powertools/logger\" ; const logger = new Logger (); const lambdaHandler = async () => { logger . addContext ( context ); logger . info ( \"This is an INFO log with some context\" ); }; Method 3, using a class decorator: handler.ts 1 2 3 4 5 6 7 8 9 10 11 12 import { Logger } from \"@aws-lambda-powertools/logger\" ; const logger = new Logger (); class Lambda { @logger . injectLambdaContext () public handler () { logger . info ( \"This is an INFO log with some context\" ); } } In both case, the printed log will look like this: Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 { \"cold_start\" : true , \"function_arn\" : \"arn:aws:lambda:eu-central-1:123456789012:function:shopping-cart-api-lambda-prod-eu-central-1\" , \"function_memory_size\" : 128 , \"function_request_id\" : \"c6af9ac6-7b61-11e6-9a41-93e812345678\" , \"function_name\" : \"shopping-cart-api-lambda-prod-eu-central-1\" , \"level\" : \"INFO\" , \"message\" : \"This is an INFO log with some context\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T21:21:08.921Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } When used, this will include the following keys: Key Example cold_start : bool false function_name string shopping-cart-api-lambda-prod-eu-central-1 function_memory_size : int 128 function_arn : string arn:aws:lambda:eu-central-1:123456789012:function:shopping-cart-api-lambda-prod-eu-central-1 function_request_id : string c6af9ac6-7b61-11e6-9a41-93e812345678 Appending persistent additional log keys and values \u00b6 You can append additional persistent keys and values in the logs generated during a Lambda invocation using either mechanism: Via the Logger's appendKeys method, for all log items generated after calling this method Passing them in the Logger's constructor handler.ts Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import { Logger } from \"@aws-lambda-powertools/logger\" ; // Add persistent log keys via the constructor const logger = new Logger ({ persistentLogAttributes : { aws_account_id : \"123456789012\" , aws_region : \"eu-central-1\" , logger : { name : \"@aws-lambda-powertools/logger\" , version : \"0.0.1\" , } } }); // OR add persistent log keys to an existing Logger instance with the appendKeys method: // logger.appendKeys({ // aws_account_id: \"123456789012\", // aws_region: \"eu-central-1\", // logger: { // name: \"@aws-lambda-powertools/logger\", // version: \"0.0.1\", // } // }); const lambdaHandler : Handler = async () => { // This info log will print all extra custom attributes added above // Extra attributes: logger object with name and version of the logger library, awsAccountId, awsRegion logger . info ( \"This is an INFO log\" ); logger . info ( \"This is another INFO log\" ); return { foo : \"bar\" }; }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"level\" : \"INFO\" , \"message\" : \"This is an INFO log\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T21:49:58.084Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"aws_account_id\" : \"123456789012\" , \"aws_region\" : \"eu-central-1\" , \"logger\" : { \"name\" : \"@aws-lambda-powertools/logger\" , \"version\" : \"0.0.1\" } } { \"level\" : \"INFO\" , \"message\" : \"This is another INFO log\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T21:49:58.088Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"aws_account_id\" : \"123456789012\" , \"aws_region\" : \"eu-central-1\" , \"logger\" : { \"name\" : \"@aws-lambda-powertools/logger\" , \"version\" : \"0.0.1\" } } Logger will automatically ignore any key with an undefined value Appending additional log keys and values to a single log item \u00b6 You can append additional keys and values in a single log item passing them as parameters. handler.ts Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import { Logger } from \"@aws-lambda-powertools/logger\" ; const logger = new Logger (); const lambdaHandler = async () => { const myImportantVariable = { foo : \"bar\" }; // Pass additional keys and values in single log items // As second parameter logger . info ( \"This is a log with an extra variable\" , { data : myImportantVariable }); // You can also pass multiple parameters logger . info ( \"This is a log with 2 extra variables\" , { data : myImportantVariable }, { correlationIds : { myCustomCorrelationId : \"foo-bar-baz\" }} ); return { foo : \"bar\" }; }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"level\" : \"INFO\" , \"message\" : \"This is a log with an extra variable\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:06:17.463Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"data\" : { f oo : \"bar\" } } { \"level\" : \"INFO\" , \"message\" : \"This is a log with 2 extra variables\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:06:17.466Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"data\" : { \"foo\" : \"bar\" }, \"correlationIds\" : { \"myCustomCorrelationId\" : \"foo-bar-baz\" } } Logging errors \u00b6 You can log errors by using the error method and pass the error object as parameter. The error will be logged with default key name error , but you can also pass your own custom key name. handler.ts Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import { Logger } from \"@aws-lambda-powertools/logger\" ; const logger = new Logger (); const lambdaHandler = async () => { try { throw new Error ( \"Unexpected error #1\" ); } catch ( error ) { // Log information about the error using the default \"error\" key logger . error ( \"This is the first error\" , error ); } try { throw new Error ( \"Unexpected error #2\" ); } catch ( error ) { // Log information about the error using a custom \"myCustomErrorKey\" key logger . error ( \"This is the second error\" , { myCustomErrorKey : error } ); } }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"level\" : \"ERROR\" , \"message\" : \"This is an ERROR log #1\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:12:39.345Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"error\" : { \"name\" : \"Error\" , \"location\" : \"/path/to/my/source-code/my-service/handler.ts:18\" , \"message\" : \"This is the first error\" , \"stack\" : \"Error: Unexpected error #1 at lambdaHandler (/path/to/my/source-code/my-service/handler.ts:18:11) at Object.<anonymous> (/path/to/my/source-code/my-service/handler.ts:35:1) at Module._compile (node:internal/modules/cjs/loader:1108:14) at Module.m._compile (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1371:23) at Module._extensions..js (node:internal/modules/cjs/loader:1137:10) at Object.require.extensions.<computed> [as .ts] (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1374:12) at Module.load (node:internal/modules/cjs/loader:973:32) at Function.Module._load (node:internal/modules/cjs/loader:813:14) at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:76:12) at main (/path/to/my/source-code/node_modules/ts-node/src/bin.ts:331:12)\" } } { \"level\" : \"ERROR\" , \"message\" : \"This is an ERROR log #2\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:12:39.377Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"myCustomErrorKey\" : { \"name\" : \"Error\" , \"location\" : \"/path/to/my/source-code/my-service/handler.ts:24\" , \"message\" : \"This is the second error\" , \"stack\" : \"Error: Unexpected error #2 at lambdaHandler (/path/to/my/source-code/my-service/handler.ts:24:11) at Object.<anonymous> (/path/to/my/source-code/my-service/handler.ts:35:1) at Module._compile (node:internal/modules/cjs/loader:1108:14) at Module.m._compile (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1371:23) at Module._extensions..js (node:internal/modules/cjs/loader:1137:10) at Object.require.extensions.<computed> [as .ts] (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1374:12) at Module.load (node:internal/modules/cjs/loader:973:32) at Function.Module._load (node:internal/modules/cjs/loader:813:14) at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:76:12) at main (/path/to/my/source-code/node_modules/ts-node/src/bin.ts:331:12)\" } } Advanced \u00b6 Using multiple Logger instances across your code \u00b6 Logger supports quick instance cloning via the createChild method. This can be useful for example if you want to enable multiple Loggers with different logging levels in the same Lambda invocation. handler.ts Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import { Logger } from \"@aws-lambda-powertools/logger\" ; // With this logger, all the INFO logs will be printed const logger = new Logger ({ logLevel : \"INFO\" }); // With this logger, only the ERROR logs will be printed const childLogger = parentLogger . createChild ({ logLevel : \"ERROR\" }); const lambdaHandler : Handler = async () => { logger . info ( \"This is an INFO log, from the parent logger\" ); logger . error ( \"This is an ERROR log, from the parent logger\" ); childLogger . info ( \"This is an INFO log, from the child logger\" ); childLogger . error ( \"This is an ERROR log, from the child logger\" ); }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"level\" : \"INFO\" , \"message\" : \"This is an INFO log, from the parent logger\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:32:54.667Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } { \"level\" : \"ERROR\" , \"message\" : \"This is an ERROR log, from the parent logger\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:32:54.670Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } { \"level\" : \"ERROR\" , \"message\" : \"This is an ERROR log, from the child logger\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:32:54.670Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } Sampling logs \u00b6 Use sampling when you want to print all the log items generated in your code, based on a percentage of your concurrent/cold start invocations . You can do that by setting a \"sample rate\", a float value ranging from 0.0 (0%) to 1 (100%), by using a POWERTOOLS_LOGGER_SAMPLE_RATE env var or passing the sampleRateValue parameter in the Logger constructor. This number represents the probability that a Lambda invocation will print all the log items regardless of the log level setting. For example, by setting the \"sample rate\" to 0.5 , roughly 50% of your lambda invocations will print all the log items, including the debug ones. When is this useful? In production, to avoid log data pollution and reduce CloudWatch costs, developers are encouraged to use the logger with logLevel equal to ERROR or WARN . This means that only errors or warnings will be printed. However, it might still be useful to print all the logs (including debug ones) of a very small percentage of invocations to have a better understanding of the behaviour of your code in production even when there are no errors. Sampling decision happens at the Logger initialization. This means sampling may happen significantly more or less than depending on your traffic patterns, for example a steady low number of invocations and thus few cold starts. handler.ts Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import { Logger } from \"@aws-lambda-powertools/logger\" ; const logger = new Logger ({ logLevel : \"ERROR\" , sampleRateValue : 0.5 }); const lambdaHandler = async () => { // 0.5 means that you have 50% chance that these logs will be printed logger . info ( \"This is INFO log #1\" ); logger . info ( \"This is INFO log #2\" ); logger . info ( \"This is INFO log #3\" ); logger . info ( \"This is INFO log #4\" ); // Optional: refresh sample rate calculation on runtime // logger.refreshSampleRateCalculation(); }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 { \"level\" : \"INFO\" , \"message\" : \"This is INFO log #1\" , \"sampling_rate\" : \"0.5\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:59:06.334Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } { \"level\" : \"INFO\" , \"message\" : \"This is INFO log #2\" , \"sampling_rate\" : \"0.5\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:59:06.337Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } { \"level\" : \"INFO\" , \"message\" : \"This is INFO log #3\" , \"sampling_rate\" : \"0.5\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:59:06.338Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } { \"level\" : \"INFO\" , \"message\" : \"This is INFO log #4\" , \"sampling_rate\" : \"0.5\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:59:06.338Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } Custom Log formatter (Bring Your Own Formatter) \u00b6 You can customize the structure (keys and values) of your log items by passing a custom log formatter, an object that extends the LogFormatter abstract class. handler.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import { Logger } from \"@aws-lambda-powertools/logger\" ; import { MyCompanyLogFormatter } from \"./utils/formatters/MyCompanyLogFormatter\" ; const logger = new Logger ({ logFormatter : new MyCompanyLogFormatter (), logLevel : \"DEBUG\" , serviceName : \"shopping-cart-api\" , sampleRateValue : 0.5 , persistentLogAttributes : { awsAccountId : process.env.AWS_ACCOUNT_ID , logger : { name : \"@aws-lambda-powertools/logger\" , version : \"0.0.1\" } }, }); const lambdaHandler : Handler = async ( event , context ) => { logger . addContext ( context ); logger . info ( \"This is an INFO log\" , { correlationIds : { myCustomCorrelationId : \"foo-bar-baz\" } }); }; This is how the MyCompanyLogFormatter (dummy name) would look like: utils/formatters/MyCompanyLogFormatter.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import { LogFormatter } from \"@aws-lambda-powertools/logger\" ; import { LogAttributes , UnformattedAttributes } from \"@aws-lambda-powertools/logger/types\" ; // Replace this line with your own type type MyCompanyLog = LogAttributes ; class MyCompanyLogFormatter extends LogFormatter { public formatAttributes ( attributes : UnformattedAttributes ) : MyCompanyLog { return { message : attributes.message , service : attributes.serviceName , environment : attributes.environment , awsRegion : attributes.awsRegion , correlationIds : { awsRequestId : attributes.lambdaContext?.awsRequestId , xRayTraceId : attributes.xRayTraceId }, lambdaFunction : { name : attributes.lambdaContext?.functionName , arn : attributes.lambdaContext?.invokedFunctionArn , memoryLimitInMB : attributes.lambdaContext?.memoryLimitInMB , version : attributes.lambdaContext?.functionVersion , coldStart : attributes.lambdaContext?.coldStart , }, logLevel : attributes.logLevel , timestamp : this.formatTimestamp ( attributes . timestamp ), // You can extend this function logger : { sampleRateValue : attributes.sampleRateValue , }, }; } } export { MyCompanyLogFormatter }; This is how the printed log would look: Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 { \"message\" : \"This is an INFO log\" , \"service\" : \"shopping-cart-api\" , \"awsRegion\" : \"eu-central-1\" , \"correlationIds\" : { \"awsRequestId\" : \"c6af9ac6-7b61-11e6-9a41-93e812345678\" , \"xRayTraceId\" : \"abcdef123456abcdef123456abcdef123456\" , \"myCustomCorrelationId\" : \"foo-bar-baz\" }, \"lambdaFunction\" : { \"name\" : \"shopping-cart-api-lambda-prod-eu-central-1\" , \"arn\" : \"arn:aws:lambda:eu-central-1:123456789012:function:shopping-cart-api-lambda-prod-eu-central-1\" , \"memoryLimitInMB\" : 128 , \"version\" : \"$LATEST\" , \"coldStart\" : true }, \"logLevel\" : \"INFO\" , \"timestamp\" : \"2021-12-12T23:13:53.404Z\" , \"logger\" : { \"sampleRateValue\" : \"0.5\" , \"name\" : \"aws-lambda-powertools-typescript\" , \"version\" : \"0.0.1\" }, \"awsAccountId\" : \"123456789012\" }","title":"Logger"},{"location":"core/logger/#key-features","text":"Capture key fields from Lambda context, cold start and structures logging output as JSON Log Lambda context when instructed (disabled by default) Log sampling prints all logs for a percentage of invocations (disabled by default) Append additional keys to structured log at any point in time","title":"Key features"},{"location":"core/logger/#getting-started","text":"Logger requires two settings: Setting Description Environment variable Constructor parameter Logging level Sets how verbose Logger should be (INFO, by default) LOG_LEVEL logLevel Service name Sets the name of service of which the Lambda function is part of, that will be present across all log statements POWERTOOLS_SERVICE_NAME serviceName Example using AWS Serverless Application Model (SAM) handler.ts template.yaml 1 2 3 4 5 6 7 8 9 10 import { Logger } from \"@aws-lambda-powertools/logger\" ; // Logger parameters fetched from the environment variables (see template.yaml tab) const logger = new Logger (); // You can also pass the parameters in the constructor // const logger = new Logger({ // logLevel: \"INFO\", // serviceName: \"shopping-cart-api\" // }); 1 2 3 4 5 6 7 8 9 Resources : ShoppingCartApiFunction : Type : AWS::Serverless::Function Properties : Runtime : nodejs14.x Environment : Variables : LOG_LEVEL : INFO POWERTOOLS_SERVICE_NAME : shopping-cart-api","title":"Getting started"},{"location":"core/logger/#standard-structured-keys","text":"Your Logger will include the following keys to your structured logging (default log formatter): Key Example Note level : string INFO Logging level set for the Lambda function\"s invocation message : string Query performed to DynamoDB A descriptive, human-readable representation of this log item sampling_rate : float 0.1 When enabled, it prints all the logs of a percentage of invocations, e.g. 10% service : string shopping-cart-api A unique name identifier of the service this Lambda function belongs to, by default service_undefined timestamp : string 2011-10-05T14:48:00.000Z Timestamp string in simplified extended ISO format (ISO 8601) xray_trace_id : string 1-5759e988-bd862e3fe1be46a994272793 When tracing is enabled , it shows X-Ray Trace ID error : Object { name: \"Error\", location: \"/my-project/handler.ts:18\", message: \"Unexpected error #1\", stack: \"[stacktrace]\"} Optional - An object containing information about the Error passed to the logger","title":"Standard structured keys"},{"location":"core/logger/#capturing-lambda-context-info","text":"You can enrich your structured logs with key Lambda context information in multiple ways. Method 1, using a Middy middleware: handler.ts 1 2 3 4 5 6 7 8 9 10 11 import { Logger , injectLambdaContext } from \"@aws-lambda-powertools/logger\" ; import middy from '@middy/core' ; const logger = new Logger (); const lambdaHandler = async () => { logger . info ( \"This is an INFO log with some context\" ); }; const handler = middy ( lambdaHandler ) . use ( injectLambdaContext ( logger )); Method 2, calling the addContext method: handler.ts 1 2 3 4 5 6 7 8 9 10 11 import { Logger } from \"@aws-lambda-powertools/logger\" ; const logger = new Logger (); const lambdaHandler = async () => { logger . addContext ( context ); logger . info ( \"This is an INFO log with some context\" ); }; Method 3, using a class decorator: handler.ts 1 2 3 4 5 6 7 8 9 10 11 12 import { Logger } from \"@aws-lambda-powertools/logger\" ; const logger = new Logger (); class Lambda { @logger . injectLambdaContext () public handler () { logger . info ( \"This is an INFO log with some context\" ); } } In both case, the printed log will look like this: Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 { \"cold_start\" : true , \"function_arn\" : \"arn:aws:lambda:eu-central-1:123456789012:function:shopping-cart-api-lambda-prod-eu-central-1\" , \"function_memory_size\" : 128 , \"function_request_id\" : \"c6af9ac6-7b61-11e6-9a41-93e812345678\" , \"function_name\" : \"shopping-cart-api-lambda-prod-eu-central-1\" , \"level\" : \"INFO\" , \"message\" : \"This is an INFO log with some context\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T21:21:08.921Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } When used, this will include the following keys: Key Example cold_start : bool false function_name string shopping-cart-api-lambda-prod-eu-central-1 function_memory_size : int 128 function_arn : string arn:aws:lambda:eu-central-1:123456789012:function:shopping-cart-api-lambda-prod-eu-central-1 function_request_id : string c6af9ac6-7b61-11e6-9a41-93e812345678","title":"Capturing Lambda context info"},{"location":"core/logger/#appending-persistent-additional-log-keys-and-values","text":"You can append additional persistent keys and values in the logs generated during a Lambda invocation using either mechanism: Via the Logger's appendKeys method, for all log items generated after calling this method Passing them in the Logger's constructor handler.ts Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import { Logger } from \"@aws-lambda-powertools/logger\" ; // Add persistent log keys via the constructor const logger = new Logger ({ persistentLogAttributes : { aws_account_id : \"123456789012\" , aws_region : \"eu-central-1\" , logger : { name : \"@aws-lambda-powertools/logger\" , version : \"0.0.1\" , } } }); // OR add persistent log keys to an existing Logger instance with the appendKeys method: // logger.appendKeys({ // aws_account_id: \"123456789012\", // aws_region: \"eu-central-1\", // logger: { // name: \"@aws-lambda-powertools/logger\", // version: \"0.0.1\", // } // }); const lambdaHandler : Handler = async () => { // This info log will print all extra custom attributes added above // Extra attributes: logger object with name and version of the logger library, awsAccountId, awsRegion logger . info ( \"This is an INFO log\" ); logger . info ( \"This is another INFO log\" ); return { foo : \"bar\" }; }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"level\" : \"INFO\" , \"message\" : \"This is an INFO log\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T21:49:58.084Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"aws_account_id\" : \"123456789012\" , \"aws_region\" : \"eu-central-1\" , \"logger\" : { \"name\" : \"@aws-lambda-powertools/logger\" , \"version\" : \"0.0.1\" } } { \"level\" : \"INFO\" , \"message\" : \"This is another INFO log\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T21:49:58.088Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"aws_account_id\" : \"123456789012\" , \"aws_region\" : \"eu-central-1\" , \"logger\" : { \"name\" : \"@aws-lambda-powertools/logger\" , \"version\" : \"0.0.1\" } } Logger will automatically ignore any key with an undefined value","title":"Appending persistent additional log keys and values"},{"location":"core/logger/#appending-additional-log-keys-and-values-to-a-single-log-item","text":"You can append additional keys and values in a single log item passing them as parameters. handler.ts Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import { Logger } from \"@aws-lambda-powertools/logger\" ; const logger = new Logger (); const lambdaHandler = async () => { const myImportantVariable = { foo : \"bar\" }; // Pass additional keys and values in single log items // As second parameter logger . info ( \"This is a log with an extra variable\" , { data : myImportantVariable }); // You can also pass multiple parameters logger . info ( \"This is a log with 2 extra variables\" , { data : myImportantVariable }, { correlationIds : { myCustomCorrelationId : \"foo-bar-baz\" }} ); return { foo : \"bar\" }; }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"level\" : \"INFO\" , \"message\" : \"This is a log with an extra variable\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:06:17.463Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"data\" : { f oo : \"bar\" } } { \"level\" : \"INFO\" , \"message\" : \"This is a log with 2 extra variables\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:06:17.466Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"data\" : { \"foo\" : \"bar\" }, \"correlationIds\" : { \"myCustomCorrelationId\" : \"foo-bar-baz\" } }","title":"Appending additional log keys and values to a single log item"},{"location":"core/logger/#logging-errors","text":"You can log errors by using the error method and pass the error object as parameter. The error will be logged with default key name error , but you can also pass your own custom key name. handler.ts Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import { Logger } from \"@aws-lambda-powertools/logger\" ; const logger = new Logger (); const lambdaHandler = async () => { try { throw new Error ( \"Unexpected error #1\" ); } catch ( error ) { // Log information about the error using the default \"error\" key logger . error ( \"This is the first error\" , error ); } try { throw new Error ( \"Unexpected error #2\" ); } catch ( error ) { // Log information about the error using a custom \"myCustomErrorKey\" key logger . error ( \"This is the second error\" , { myCustomErrorKey : error } ); } }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \"level\" : \"ERROR\" , \"message\" : \"This is an ERROR log #1\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:12:39.345Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"error\" : { \"name\" : \"Error\" , \"location\" : \"/path/to/my/source-code/my-service/handler.ts:18\" , \"message\" : \"This is the first error\" , \"stack\" : \"Error: Unexpected error #1 at lambdaHandler (/path/to/my/source-code/my-service/handler.ts:18:11) at Object.<anonymous> (/path/to/my/source-code/my-service/handler.ts:35:1) at Module._compile (node:internal/modules/cjs/loader:1108:14) at Module.m._compile (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1371:23) at Module._extensions..js (node:internal/modules/cjs/loader:1137:10) at Object.require.extensions.<computed> [as .ts] (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1374:12) at Module.load (node:internal/modules/cjs/loader:973:32) at Function.Module._load (node:internal/modules/cjs/loader:813:14) at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:76:12) at main (/path/to/my/source-code/node_modules/ts-node/src/bin.ts:331:12)\" } } { \"level\" : \"ERROR\" , \"message\" : \"This is an ERROR log #2\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:12:39.377Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" , \"myCustomErrorKey\" : { \"name\" : \"Error\" , \"location\" : \"/path/to/my/source-code/my-service/handler.ts:24\" , \"message\" : \"This is the second error\" , \"stack\" : \"Error: Unexpected error #2 at lambdaHandler (/path/to/my/source-code/my-service/handler.ts:24:11) at Object.<anonymous> (/path/to/my/source-code/my-service/handler.ts:35:1) at Module._compile (node:internal/modules/cjs/loader:1108:14) at Module.m._compile (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1371:23) at Module._extensions..js (node:internal/modules/cjs/loader:1137:10) at Object.require.extensions.<computed> [as .ts] (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1374:12) at Module.load (node:internal/modules/cjs/loader:973:32) at Function.Module._load (node:internal/modules/cjs/loader:813:14) at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:76:12) at main (/path/to/my/source-code/node_modules/ts-node/src/bin.ts:331:12)\" } }","title":"Logging errors"},{"location":"core/logger/#advanced","text":"","title":"Advanced"},{"location":"core/logger/#using-multiple-logger-instances-across-your-code","text":"Logger supports quick instance cloning via the createChild method. This can be useful for example if you want to enable multiple Loggers with different logging levels in the same Lambda invocation. handler.ts Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import { Logger } from \"@aws-lambda-powertools/logger\" ; // With this logger, all the INFO logs will be printed const logger = new Logger ({ logLevel : \"INFO\" }); // With this logger, only the ERROR logs will be printed const childLogger = parentLogger . createChild ({ logLevel : \"ERROR\" }); const lambdaHandler : Handler = async () => { logger . info ( \"This is an INFO log, from the parent logger\" ); logger . error ( \"This is an ERROR log, from the parent logger\" ); childLogger . info ( \"This is an INFO log, from the child logger\" ); childLogger . error ( \"This is an ERROR log, from the child logger\" ); }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { \"level\" : \"INFO\" , \"message\" : \"This is an INFO log, from the parent logger\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:32:54.667Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } { \"level\" : \"ERROR\" , \"message\" : \"This is an ERROR log, from the parent logger\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:32:54.670Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } { \"level\" : \"ERROR\" , \"message\" : \"This is an ERROR log, from the child logger\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:32:54.670Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" }","title":"Using multiple Logger instances across your code"},{"location":"core/logger/#sampling-logs","text":"Use sampling when you want to print all the log items generated in your code, based on a percentage of your concurrent/cold start invocations . You can do that by setting a \"sample rate\", a float value ranging from 0.0 (0%) to 1 (100%), by using a POWERTOOLS_LOGGER_SAMPLE_RATE env var or passing the sampleRateValue parameter in the Logger constructor. This number represents the probability that a Lambda invocation will print all the log items regardless of the log level setting. For example, by setting the \"sample rate\" to 0.5 , roughly 50% of your lambda invocations will print all the log items, including the debug ones. When is this useful? In production, to avoid log data pollution and reduce CloudWatch costs, developers are encouraged to use the logger with logLevel equal to ERROR or WARN . This means that only errors or warnings will be printed. However, it might still be useful to print all the logs (including debug ones) of a very small percentage of invocations to have a better understanding of the behaviour of your code in production even when there are no errors. Sampling decision happens at the Logger initialization. This means sampling may happen significantly more or less than depending on your traffic patterns, for example a steady low number of invocations and thus few cold starts. handler.ts Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import { Logger } from \"@aws-lambda-powertools/logger\" ; const logger = new Logger ({ logLevel : \"ERROR\" , sampleRateValue : 0.5 }); const lambdaHandler = async () => { // 0.5 means that you have 50% chance that these logs will be printed logger . info ( \"This is INFO log #1\" ); logger . info ( \"This is INFO log #2\" ); logger . info ( \"This is INFO log #3\" ); logger . info ( \"This is INFO log #4\" ); // Optional: refresh sample rate calculation on runtime // logger.refreshSampleRateCalculation(); }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 { \"level\" : \"INFO\" , \"message\" : \"This is INFO log #1\" , \"sampling_rate\" : \"0.5\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:59:06.334Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } { \"level\" : \"INFO\" , \"message\" : \"This is INFO log #2\" , \"sampling_rate\" : \"0.5\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:59:06.337Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } { \"level\" : \"INFO\" , \"message\" : \"This is INFO log #3\" , \"sampling_rate\" : \"0.5\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:59:06.338Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" } { \"level\" : \"INFO\" , \"message\" : \"This is INFO log #4\" , \"sampling_rate\" : \"0.5\" , \"service\" : \"shopping-cart-api\" , \"timestamp\" : \"2021-12-12T22:59:06.338Z\" , \"xray_trace_id\" : \"abcdef123456abcdef123456abcdef123456\" }","title":"Sampling logs"},{"location":"core/logger/#custom-log-formatter-bring-your-own-formatter","text":"You can customize the structure (keys and values) of your log items by passing a custom log formatter, an object that extends the LogFormatter abstract class. handler.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import { Logger } from \"@aws-lambda-powertools/logger\" ; import { MyCompanyLogFormatter } from \"./utils/formatters/MyCompanyLogFormatter\" ; const logger = new Logger ({ logFormatter : new MyCompanyLogFormatter (), logLevel : \"DEBUG\" , serviceName : \"shopping-cart-api\" , sampleRateValue : 0.5 , persistentLogAttributes : { awsAccountId : process.env.AWS_ACCOUNT_ID , logger : { name : \"@aws-lambda-powertools/logger\" , version : \"0.0.1\" } }, }); const lambdaHandler : Handler = async ( event , context ) => { logger . addContext ( context ); logger . info ( \"This is an INFO log\" , { correlationIds : { myCustomCorrelationId : \"foo-bar-baz\" } }); }; This is how the MyCompanyLogFormatter (dummy name) would look like: utils/formatters/MyCompanyLogFormatter.ts 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import { LogFormatter } from \"@aws-lambda-powertools/logger\" ; import { LogAttributes , UnformattedAttributes } from \"@aws-lambda-powertools/logger/types\" ; // Replace this line with your own type type MyCompanyLog = LogAttributes ; class MyCompanyLogFormatter extends LogFormatter { public formatAttributes ( attributes : UnformattedAttributes ) : MyCompanyLog { return { message : attributes.message , service : attributes.serviceName , environment : attributes.environment , awsRegion : attributes.awsRegion , correlationIds : { awsRequestId : attributes.lambdaContext?.awsRequestId , xRayTraceId : attributes.xRayTraceId }, lambdaFunction : { name : attributes.lambdaContext?.functionName , arn : attributes.lambdaContext?.invokedFunctionArn , memoryLimitInMB : attributes.lambdaContext?.memoryLimitInMB , version : attributes.lambdaContext?.functionVersion , coldStart : attributes.lambdaContext?.coldStart , }, logLevel : attributes.logLevel , timestamp : this.formatTimestamp ( attributes . timestamp ), // You can extend this function logger : { sampleRateValue : attributes.sampleRateValue , }, }; } } export { MyCompanyLogFormatter }; This is how the printed log would look: Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 { \"message\" : \"This is an INFO log\" , \"service\" : \"shopping-cart-api\" , \"awsRegion\" : \"eu-central-1\" , \"correlationIds\" : { \"awsRequestId\" : \"c6af9ac6-7b61-11e6-9a41-93e812345678\" , \"xRayTraceId\" : \"abcdef123456abcdef123456abcdef123456\" , \"myCustomCorrelationId\" : \"foo-bar-baz\" }, \"lambdaFunction\" : { \"name\" : \"shopping-cart-api-lambda-prod-eu-central-1\" , \"arn\" : \"arn:aws:lambda:eu-central-1:123456789012:function:shopping-cart-api-lambda-prod-eu-central-1\" , \"memoryLimitInMB\" : 128 , \"version\" : \"$LATEST\" , \"coldStart\" : true }, \"logLevel\" : \"INFO\" , \"timestamp\" : \"2021-12-12T23:13:53.404Z\" , \"logger\" : { \"sampleRateValue\" : \"0.5\" , \"name\" : \"aws-lambda-powertools-typescript\" , \"version\" : \"0.0.1\" }, \"awsAccountId\" : \"123456789012\" }","title":"Custom Log formatter (Bring Your Own Formatter)"},{"location":"core/metrics/","text":"Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF) . These metrics can be visualized through Amazon CloudWatch Console . Key features \u00b6 Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob) Validate against common metric definitions mistakes (metric unit, values, max dimensions, max metrics, etc) Metrics are created asynchronously by CloudWatch service, no custom stacks needed Context manager to create a one off metric with a different dimension Terminologies \u00b6 If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility: Namespace . It's the highest level container that will group multiple metrics from multiple services for a given application, for example ServerlessEcommerce . Dimensions . Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example ColdStart metric by Payment service . Metric terminology, visually explained Getting started \u00b6 Metric has two global settings that will be used across all metrics emitted: Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. ServerlessAirline POWERTOOLS_METRICS_NAMESPACE namespace Service Optionally, sets service metric dimension across all metrics e.g. payment POWERTOOLS_SERVICE_NAME service Use your application or main service as the metric namespace to easily group all metrics Example using AWS Serverless Application Model (SAM) template.yml index.ts 1 2 3 4 5 6 7 8 9 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : Runtime : nodejs14.x Environment : Variables : POWERTOOLS_SERVICE_NAME : payment POWERTOOLS_METRICS_NAMESPACE : ServerlessAirline 1 2 3 4 5 6 7 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; // Sets metric namespace and service via env var const metrics = new Metrics (); // OR Sets metric namespace, and service as a metrics parameters const metrics = new Metrics ({ namespace : \"ServerlessAirline\" , service : \"orders\" }); You can initialize Metrics anywhere in your code - It'll keep track of your aggregate metrics in memory. Creating metrics \u00b6 You can create metrics using addMetric , and you can create dimensions for all your aggregate metrics using addDimension method. Metrics Metrics with custom dimensions 1 2 3 4 5 6 7 8 9 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; import { Context } from 'aws-lambda' ; const metrics = new Metrics ({ namespace : \"ServerlessAirline\" , service : \"orders\" }); export const handler = async ( event : any , context : Context ) => { metrics . addMetric ( 'SuccessfulBooking' , MetricUnits . Count , 1 ); } 1 2 3 4 5 6 7 8 9 10 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; import { Context } from 'aws-lambda' ; const metrics = new Metrics ({ namespace : \"ServerlessAirline\" , service : \"orders\" }); export const handler = async ( event : any , context : Context ) => { metrics . addDimension ( 'environment' , 'prod' ); metrics . addMetric ( 'SuccessfulBooking' , MetricUnits . Count , 1 ); } Autocomplete Metric Units MetricUnit enum facilitate finding a supported metric unit by CloudWatch. Alternatively, you can pass the value as a string if you already know them e.g. \"Count\". Metrics overflow CloudWatch EMF supports a max of 100 metrics per batch. Metrics utility will flush all metrics when adding the 100th metric. Subsequent metrics, e.g. 101th, will be aggregated into a new EMF object, for your convenience. Do not create metrics or dimensions outside the handler Metrics or dimensions added in the global scope will only be added during cold start. Disregard if that's the intended behaviour. Adding default dimensions \u00b6 You can use setDefaultDimensions method to persist dimensions across Lambda invocations. If you'd like to remove them at some point, you can use clearDefaultDimensions method. setDefaultDimensions method with logMetrics decorator 1 2 3 4 5 6 7 8 9 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; import { Context } from 'aws-lambda' ; const metrics = new Metrics ({ namespace : \"ServerlessAirline\" , service : \"orders\" }); metrics . setDefaultDimensions ({ 'environment' : 'prod' , 'anotherDimension' : 'whatever' }); export const handler = async ( event : any , context : Context ) => { metrics . addMetric ( 'SuccessfulBooking' , MetricUnits . Count , 1 ); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; import { Context , Callback } from 'aws-lambda' ; const metrics = new Metrics ({ namespace : \"ServerlessAirline\" , service : \"orders\" }); const DEFAULT_DIMENSIONS = { \"environment\" : \"prod\" , \"another\" : \"one\" }; export class MyFunction { @metrics . logMetrics ({ defaultDimensions : DEFAULT_DIMENSIONS }) public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { metrics . addMetric ( 'SuccessfulBooking' , MetricUnits . Count , 1 ); } Flushing metrics \u00b6 As you finish adding all your metrics, you need to serialize and flush them to standard output. Using Decorator \u00b6 You can do that automatically with the logMetrics decorator. Warning Decorators can only be attached to a class declaration, method, accessor, property, or parameter. Therefore, if you are more into standard function, check the next section instead. See the official doc for more details. This decorator also validates , serializes , and flushes all your metrics. During metrics validation, if no metrics are provided then a warning will be logged, but no exception will be raised. 1 2 3 4 5 6 7 8 9 10 11 12 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; import { Context , Callback } from 'aws-lambda' ; const metrics = new Metrics ({ namespace : \"ExampleApplication\" , service : \"ExampleService\" }); export class MyFunction { @metrics . logMetrics () public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { metrics . addMetric ( 'BookingConfirmation' , MetricUnits . Count , 1 ); } } Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 { \"BookingConfirmation\" : 1.0 , \"_aws\" : { \"Timestamp\" : 1592234975665 , \"CloudWatchMetrics\" : [ { \"Namespace\" : \"ExampleApplication\" , \"Dimensions\" : [ [ \"service\" ] ], \"Metrics\" : [ { \"Name\" : \"BookingConfirmation\" , \"Unit\" : \"Count\" } ] } ] }, \"service\" : \"ExampleService\" } Metric validation If metrics are provided, and any of the following criteria are not met, SchemaValidationError exception will be raised: Maximum of 9 dimensions Namespace is set, and no more than one Metric units must be supported by CloudWatch Manually \u00b6 If you prefer not to use logMetrics decorator because you might want to encapsulate additional logic or avoid having to go for classes encapsulation when doing so, you can manually flush with purgeStoredMetrics and clear metrics as follows: Warning Metrics, dimensions and namespace validation still applies. 1 2 3 4 5 6 7 8 9 10 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; const metrics = new Metrics (); const lambdaHandler : Handler = async () => { metrics . addMetric ( 'test-metric' , MetricUnits . Count , 10 ); const metricsObject = metrics . serializeMetrics (); metrics . purgeStoredMetrics (); console . log ( JSON . stringify ( metricsObject )); }; Raising SchemaValidationError on empty metrics \u00b6 If you want to ensure that at least one metric is emitted, you can pass raiseOnEmptyMetrics to the logMetrics decorator: 1 2 3 4 5 6 7 8 9 10 11 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; const metrics = new Metrics (); class Lambda implements LambdaInterface { @metrics . logMetrics ({ raiseOnEmptyMetrics : true }) public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { // This will throw an error unless at least one metric is added } } Capturing cold start metric \u00b6 You can optionally capture cold start metrics with logMetrics decorator via captureColdStartMetric param. 1 2 3 4 5 6 7 8 9 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; const metrics = new Metrics (); class Lambda implements LambdaInterface { @metrics . logMetrics ({ captureColdStartMetric : true }) public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { ... If it's a cold start invocation, this feature will: Create a separate EMF blob solely containing a metric named ColdStart Add function_name and service dimensions This has the advantage of keeping cold start metric separate from your application metrics, where you might have unrelated dimensions. We do not emit 0 as a value for ColdStart metric for cost reasons. Let us know if you'd prefer a flag to override it Advanced \u00b6 Adding metadata \u00b6 You can add high-cardinality data as part of your Metrics log with addMetadata method. This is useful when you want to search highly contextual information along with your metrics in your logs. Info This will not be available during metrics visualization - Use dimensions for this purpose 1 2 3 4 5 6 7 8 9 10 11 12 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; const metrics = new Metrics (); class Lambda implements LambdaInterface { @metrics . logMetrics () public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { metrics . addMetadata ( 'booking_id' , 'booking_uuid' ); //Your Logic } } Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"SuccessfulBooking\" : 1.0 , \"_aws\" : { \"Timestamp\" : 1592234975665 , \"CloudWatchMetrics\" : [ { \"Namespace\" : \"ExampleApplication\" , \"Dimensions\" : [ [ \"service\" ] ], \"Metrics\" : [ { \"Name\" : \"SuccessfulBooking\" , \"Unit\" : \"Count\" } ] } ] }, \"service\" : \"booking\" , \"booking_id\" : \"booking_uuid\" } Single metric with a different dimension \u00b6 CloudWatch EMF uses the same dimensions across all your metrics. Use singleMetric if you have a metric that should have different dimensions. Info Generally, this would be an edge case since you pay for unique metric . Keep the following formula in mind: unique metric = (metric_name + dimension_name + dimension_value) 1 2 3 4 5 6 7 8 9 10 11 class Lambda implements LambdaInterface { @metrics . logMetrics () public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { const singleMetric = metrics . singleMetric (); metrics . addDimension ( 'OuterDimension' , 'true' ); singleMetric . addDimension ( 'InnerDimension' , 'true' ); metrics . addMetric ( 'test-metric' , MetricUnits . Count , 10 ); singleMetric . addMetric ( 'single-metric' , MetricUnits . Percent , 50 ); } }","title":"Metrics"},{"location":"core/metrics/#key-features","text":"Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob) Validate against common metric definitions mistakes (metric unit, values, max dimensions, max metrics, etc) Metrics are created asynchronously by CloudWatch service, no custom stacks needed Context manager to create a one off metric with a different dimension","title":"Key features"},{"location":"core/metrics/#terminologies","text":"If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility: Namespace . It's the highest level container that will group multiple metrics from multiple services for a given application, for example ServerlessEcommerce . Dimensions . Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example ColdStart metric by Payment service . Metric terminology, visually explained","title":"Terminologies"},{"location":"core/metrics/#getting-started","text":"Metric has two global settings that will be used across all metrics emitted: Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. ServerlessAirline POWERTOOLS_METRICS_NAMESPACE namespace Service Optionally, sets service metric dimension across all metrics e.g. payment POWERTOOLS_SERVICE_NAME service Use your application or main service as the metric namespace to easily group all metrics Example using AWS Serverless Application Model (SAM) template.yml index.ts 1 2 3 4 5 6 7 8 9 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : Runtime : nodejs14.x Environment : Variables : POWERTOOLS_SERVICE_NAME : payment POWERTOOLS_METRICS_NAMESPACE : ServerlessAirline 1 2 3 4 5 6 7 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; // Sets metric namespace and service via env var const metrics = new Metrics (); // OR Sets metric namespace, and service as a metrics parameters const metrics = new Metrics ({ namespace : \"ServerlessAirline\" , service : \"orders\" }); You can initialize Metrics anywhere in your code - It'll keep track of your aggregate metrics in memory.","title":"Getting started"},{"location":"core/metrics/#creating-metrics","text":"You can create metrics using addMetric , and you can create dimensions for all your aggregate metrics using addDimension method. Metrics Metrics with custom dimensions 1 2 3 4 5 6 7 8 9 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; import { Context } from 'aws-lambda' ; const metrics = new Metrics ({ namespace : \"ServerlessAirline\" , service : \"orders\" }); export const handler = async ( event : any , context : Context ) => { metrics . addMetric ( 'SuccessfulBooking' , MetricUnits . Count , 1 ); } 1 2 3 4 5 6 7 8 9 10 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; import { Context } from 'aws-lambda' ; const metrics = new Metrics ({ namespace : \"ServerlessAirline\" , service : \"orders\" }); export const handler = async ( event : any , context : Context ) => { metrics . addDimension ( 'environment' , 'prod' ); metrics . addMetric ( 'SuccessfulBooking' , MetricUnits . Count , 1 ); } Autocomplete Metric Units MetricUnit enum facilitate finding a supported metric unit by CloudWatch. Alternatively, you can pass the value as a string if you already know them e.g. \"Count\". Metrics overflow CloudWatch EMF supports a max of 100 metrics per batch. Metrics utility will flush all metrics when adding the 100th metric. Subsequent metrics, e.g. 101th, will be aggregated into a new EMF object, for your convenience. Do not create metrics or dimensions outside the handler Metrics or dimensions added in the global scope will only be added during cold start. Disregard if that's the intended behaviour.","title":"Creating metrics"},{"location":"core/metrics/#adding-default-dimensions","text":"You can use setDefaultDimensions method to persist dimensions across Lambda invocations. If you'd like to remove them at some point, you can use clearDefaultDimensions method. setDefaultDimensions method with logMetrics decorator 1 2 3 4 5 6 7 8 9 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; import { Context } from 'aws-lambda' ; const metrics = new Metrics ({ namespace : \"ServerlessAirline\" , service : \"orders\" }); metrics . setDefaultDimensions ({ 'environment' : 'prod' , 'anotherDimension' : 'whatever' }); export const handler = async ( event : any , context : Context ) => { metrics . addMetric ( 'SuccessfulBooking' , MetricUnits . Count , 1 ); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; import { Context , Callback } from 'aws-lambda' ; const metrics = new Metrics ({ namespace : \"ServerlessAirline\" , service : \"orders\" }); const DEFAULT_DIMENSIONS = { \"environment\" : \"prod\" , \"another\" : \"one\" }; export class MyFunction { @metrics . logMetrics ({ defaultDimensions : DEFAULT_DIMENSIONS }) public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { metrics . addMetric ( 'SuccessfulBooking' , MetricUnits . Count , 1 ); }","title":"Adding default dimensions"},{"location":"core/metrics/#flushing-metrics","text":"As you finish adding all your metrics, you need to serialize and flush them to standard output.","title":"Flushing metrics"},{"location":"core/metrics/#using-decorator","text":"You can do that automatically with the logMetrics decorator. Warning Decorators can only be attached to a class declaration, method, accessor, property, or parameter. Therefore, if you are more into standard function, check the next section instead. See the official doc for more details. This decorator also validates , serializes , and flushes all your metrics. During metrics validation, if no metrics are provided then a warning will be logged, but no exception will be raised. 1 2 3 4 5 6 7 8 9 10 11 12 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; import { Context , Callback } from 'aws-lambda' ; const metrics = new Metrics ({ namespace : \"ExampleApplication\" , service : \"ExampleService\" }); export class MyFunction { @metrics . logMetrics () public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { metrics . addMetric ( 'BookingConfirmation' , MetricUnits . Count , 1 ); } } Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 { \"BookingConfirmation\" : 1.0 , \"_aws\" : { \"Timestamp\" : 1592234975665 , \"CloudWatchMetrics\" : [ { \"Namespace\" : \"ExampleApplication\" , \"Dimensions\" : [ [ \"service\" ] ], \"Metrics\" : [ { \"Name\" : \"BookingConfirmation\" , \"Unit\" : \"Count\" } ] } ] }, \"service\" : \"ExampleService\" } Metric validation If metrics are provided, and any of the following criteria are not met, SchemaValidationError exception will be raised: Maximum of 9 dimensions Namespace is set, and no more than one Metric units must be supported by CloudWatch","title":"Using Decorator"},{"location":"core/metrics/#manually","text":"If you prefer not to use logMetrics decorator because you might want to encapsulate additional logic or avoid having to go for classes encapsulation when doing so, you can manually flush with purgeStoredMetrics and clear metrics as follows: Warning Metrics, dimensions and namespace validation still applies. 1 2 3 4 5 6 7 8 9 10 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; const metrics = new Metrics (); const lambdaHandler : Handler = async () => { metrics . addMetric ( 'test-metric' , MetricUnits . Count , 10 ); const metricsObject = metrics . serializeMetrics (); metrics . purgeStoredMetrics (); console . log ( JSON . stringify ( metricsObject )); };","title":"Manually"},{"location":"core/metrics/#raising-schemavalidationerror-on-empty-metrics","text":"If you want to ensure that at least one metric is emitted, you can pass raiseOnEmptyMetrics to the logMetrics decorator: 1 2 3 4 5 6 7 8 9 10 11 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; const metrics = new Metrics (); class Lambda implements LambdaInterface { @metrics . logMetrics ({ raiseOnEmptyMetrics : true }) public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { // This will throw an error unless at least one metric is added } }","title":"Raising SchemaValidationError on empty metrics"},{"location":"core/metrics/#capturing-cold-start-metric","text":"You can optionally capture cold start metrics with logMetrics decorator via captureColdStartMetric param. 1 2 3 4 5 6 7 8 9 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; const metrics = new Metrics (); class Lambda implements LambdaInterface { @metrics . logMetrics ({ captureColdStartMetric : true }) public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { ... If it's a cold start invocation, this feature will: Create a separate EMF blob solely containing a metric named ColdStart Add function_name and service dimensions This has the advantage of keeping cold start metric separate from your application metrics, where you might have unrelated dimensions. We do not emit 0 as a value for ColdStart metric for cost reasons. Let us know if you'd prefer a flag to override it","title":"Capturing cold start metric"},{"location":"core/metrics/#advanced","text":"","title":"Advanced"},{"location":"core/metrics/#adding-metadata","text":"You can add high-cardinality data as part of your Metrics log with addMetadata method. This is useful when you want to search highly contextual information along with your metrics in your logs. Info This will not be available during metrics visualization - Use dimensions for this purpose 1 2 3 4 5 6 7 8 9 10 11 12 import { Metrics , MetricUnits } from '@aws-lambda-powertools/metrics' ; const metrics = new Metrics (); class Lambda implements LambdaInterface { @metrics . logMetrics () public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { metrics . addMetadata ( 'booking_id' , 'booking_uuid' ); //Your Logic } } Example CloudWatch Logs excerpt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { \"SuccessfulBooking\" : 1.0 , \"_aws\" : { \"Timestamp\" : 1592234975665 , \"CloudWatchMetrics\" : [ { \"Namespace\" : \"ExampleApplication\" , \"Dimensions\" : [ [ \"service\" ] ], \"Metrics\" : [ { \"Name\" : \"SuccessfulBooking\" , \"Unit\" : \"Count\" } ] } ] }, \"service\" : \"booking\" , \"booking_id\" : \"booking_uuid\" }","title":"Adding metadata"},{"location":"core/metrics/#single-metric-with-a-different-dimension","text":"CloudWatch EMF uses the same dimensions across all your metrics. Use singleMetric if you have a metric that should have different dimensions. Info Generally, this would be an edge case since you pay for unique metric . Keep the following formula in mind: unique metric = (metric_name + dimension_name + dimension_value) 1 2 3 4 5 6 7 8 9 10 11 class Lambda implements LambdaInterface { @metrics . logMetrics () public handler < TEvent , TResult > ( _event : TEvent , _context : Context , _callback : Callback < TResult > ) : void | Promise < TResult > { const singleMetric = metrics . singleMetric (); metrics . addDimension ( 'OuterDimension' , 'true' ); singleMetric . addDimension ( 'InnerDimension' , 'true' ); metrics . addMetric ( 'test-metric' , MetricUnits . Count , 10 ); singleMetric . addMetric ( 'single-metric' , MetricUnits . Percent , 50 ); } }","title":"Single metric with a different dimension"},{"location":"core/tracer/","text":"Tracer is an opinionated thin wrapper for AWS X-Ray SDK for Node.js . Key features \u00b6 Auto capture cold start and service name as annotations, and responses or full exceptions as metadata Auto-disable when not running in AWS Lambda environment Support tracing functions via decorators, middleware, and manual instrumentation Support tracing AWS SDK v2 and v3 via AWS X-Ray SDK for Node.js Getting started \u00b6 Permissions \u00b6 Before your use this utility, your AWS Lambda function must have permissions to send traces to AWS X-Ray. Example using AWS Serverless Application Model (SAM) template.yml 1 2 3 4 5 6 7 8 9 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : Runtime : nodejs14.x Tracing : Active Environment : Variables : POWERTOOLS_SERVICE_NAME : example Lambda handler \u00b6 You can quickly start by importing the Tracer class, initialize it outside the Lambda handler, and instrument your function. Middleware Decorator Manual 1 2 3 4 5 6 7 8 9 import { Tracer } from '@aws-lambda-powertools/tracer' ; import middy from '@middy/core' ; const tracer = Tracer (); // Sets service via env var // OR tracer = Tracer({ service: 'example' }); export const handler = middy ( async ( _event : any , _context : any ) => { ... }). use ( captureLambdaHandler ( tracer )); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = Tracer (); // Sets service via env var // OR tracer = Tracer({ service: 'example' }); class Lambda { @tracer . captureLambdaHanlder () public handler ( event : any , context : any ) { ... } } export const handlerClass = new Lambda (); export const handler = handlerClass . handler ; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = Tracer (); // Sets service via env var // OR tracer = Tracer({ service: 'example' }); export const handler = async ( _event : any , context : any ) => { const segment = tracer . getSegment (); // This is the facade segment (the one that is created by AWS Lambda) // Create subsegment for the function const handlerSegment = segment . addNewSubsegment ( `## ${ context . functionName } ` ); tracer . annotateColdStart (); tracer . addServiceNameAnnotation (); let res ; try { res = ... // Add the response as metadata tracer . addResponseAsMetadata ( res , context . functionName ); } catch ( err ) { // Add the error as metadata tracer . addErrorAsMetadata ( err as Error ); } // Close subsegment (the AWS Lambda one is closed automatically) handlerSegment . close (); return res ; } When using the captureLambdaHandler decorator or middleware, Tracer performs these additional tasks to ease operations: Handles the lifecycle of the subsegment Creates a ColdStart annotation to easily filter traces that have had an initialization overhead Captures any response, or full exceptions generated by the handler, and include as tracing metadata Annotations & Metadata \u00b6 Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions. Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional context for an operation using any native object. Annotations Metadata You can add annotations using putAnnotation method. 1 2 3 4 5 6 7 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = new Tracer ({ serviceName : 'my-service' }); export const handler = async ( _event : any , _context : any ) => { tracer . putAnnotation ( 'PaymentStatus' , \"SUCCESS\" ); } You can add metadata using putMetadata method. 1 2 3 4 5 6 7 8 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = new Tracer ({ serviceName : 'my-service' }); export const handler = async ( _event : any , _context : any ) => { const res = someLogic (); tracer . putMetadata ( 'PaymentResponse' , res ); } Methods \u00b6 You can trace other methods using the captureMethod decorator or manual instrumentation. Info We currently support a middleware for tracing methods, let us know if you'd like to see one! Decorator Manual 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = Tracer (); class Lambda { @tracer . captureMethod () public getChargeId () : string { ... return 'foo bar' } public handler ( event : any , context : any ) { const chargeId = this . getChargeId (); const payment = collectPayment ( chargeId ); ... } } export const handlerClass = new Lambda (); export const getChargeId = handlerClass . getChargeId ; export const handler = handlerClass . handler ; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import { Tracer } from '@aws-lambda-powertools/tracer' ; import { Segment } from 'aws-xray-sdk-core' ; const tracer = new Tracer ({ serviceName : 'my-service' }); const chargeId = async () => { // Create subsegment & set it as active const subsegment = new Subsegment ( `### chargeId` ); tracer . setSegment ( subsegment ); let res ; try { res = await someLogic (); // Do something // Add the response as metadata tracer . putMetadata ( `chargeId response` , data ); } catch ( err ) { // Add the error as metadata subsegment . addError ( err , false ); } // Close subsegment subsegment . close (); return res ; } export const handler = async ( _event : any , _context : any ) => { const chargeId = this . getChargeId (); const payment = collectPayment ( chargeId ); ... } Advanced \u00b6 Patching AWS SDK clients \u00b6 Tracer can patch AWS SDK clients and create traces when your application makes calls to AWS services. Info The following snippet assumes you are using AWS SDK v3 for JavaScript You can patch any AWS SDK clients by calling captureAWSv3Client method: index.ts 1 2 3 4 5 6 import { S3Client } from \"@aws-sdk/client-s3\" ; import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = new Tracer (); const client = new S3Client ({}); tracer . captureAWSv3Client ( client ); Info The following two snippets assume you are using AWS SDK v2 for JavaScript You can patch all AWS SDK clients by calling captureAWS method: index.ts 1 2 3 4 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = new Tracer (); const AWS = tracer . captureAWS ( require ( 'aws-sdk' )); If you're looking to shave a few microseconds, or milliseconds depending on your function memory configuration, you can patch specific clients using captureAWSClient : index.ts 1 2 3 4 5 import { S3 } from \"aws-sdk\" ; import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = new Tracer (); const s3 = tracer . captureAWSClient ( new S3 ({ apiVersion : \"2006-03-01\" })); Disabling response auto-capture \u00b6 Use POWERTOOLS_TRACER_CAPTURE_RESPONSE=false environment variable to instruct Tracer not to serialize function responses as metadata. This is commonly useful in three scenarios You might return sensitive information you don't want it to be added to your traces You might manipulate streaming objects that can be read only once ; this prevents subsequent calls from being empty You might return more than 64K of data e.g., message too long error Disabling exception auto-capture \u00b6 Use POWERTOOLS_TRACER_CAPTURE_ERROR=false environment variable to instruct Tracer not to serialize exceptions as metadata. Commonly useful in one scenario You might return sensitive information from exceptions, stack traces you might not control Escape hatch mechanism \u00b6 You can use tracer.provider attribute to access all methods provided by the AWS X-Ray SDK . This is useful when you need a feature available in X-Ray that is not available in the Tracer utility, for example SQL queries tracing , or a custom logger . index.ts 1 2 3 4 5 6 import { Logger } from '@aws-lambda-powertools/logger' ; import { Tracer } from '@aws-lambda-powertools/tracer' ; const logger = new Logger (); const tracer = new Tracer () tracer . provider . setLogger ( logger ) Testing your code \u00b6 Tracer is disabled by default when not running in the AWS Lambda environment - This means no code changes or environment variables to be set. Tips \u00b6 Use annotations on key operations to slice and dice traces, create unique views, and create metrics from it via Trace Groups Use a namespace when adding metadata to group data more easily Annotations and metadata are added to the current subsegment opened. If you want them in a specific subsegment, create one via the escape hatch mechanism","title":"Tracer"},{"location":"core/tracer/#key-features","text":"Auto capture cold start and service name as annotations, and responses or full exceptions as metadata Auto-disable when not running in AWS Lambda environment Support tracing functions via decorators, middleware, and manual instrumentation Support tracing AWS SDK v2 and v3 via AWS X-Ray SDK for Node.js","title":"Key features"},{"location":"core/tracer/#getting-started","text":"","title":"Getting started"},{"location":"core/tracer/#permissions","text":"Before your use this utility, your AWS Lambda function must have permissions to send traces to AWS X-Ray. Example using AWS Serverless Application Model (SAM) template.yml 1 2 3 4 5 6 7 8 9 Resources : HelloWorldFunction : Type : AWS::Serverless::Function Properties : Runtime : nodejs14.x Tracing : Active Environment : Variables : POWERTOOLS_SERVICE_NAME : example","title":"Permissions"},{"location":"core/tracer/#lambda-handler","text":"You can quickly start by importing the Tracer class, initialize it outside the Lambda handler, and instrument your function. Middleware Decorator Manual 1 2 3 4 5 6 7 8 9 import { Tracer } from '@aws-lambda-powertools/tracer' ; import middy from '@middy/core' ; const tracer = Tracer (); // Sets service via env var // OR tracer = Tracer({ service: 'example' }); export const handler = middy ( async ( _event : any , _context : any ) => { ... }). use ( captureLambdaHandler ( tracer )); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = Tracer (); // Sets service via env var // OR tracer = Tracer({ service: 'example' }); class Lambda { @tracer . captureLambdaHanlder () public handler ( event : any , context : any ) { ... } } export const handlerClass = new Lambda (); export const handler = handlerClass . handler ; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = Tracer (); // Sets service via env var // OR tracer = Tracer({ service: 'example' }); export const handler = async ( _event : any , context : any ) => { const segment = tracer . getSegment (); // This is the facade segment (the one that is created by AWS Lambda) // Create subsegment for the function const handlerSegment = segment . addNewSubsegment ( `## ${ context . functionName } ` ); tracer . annotateColdStart (); tracer . addServiceNameAnnotation (); let res ; try { res = ... // Add the response as metadata tracer . addResponseAsMetadata ( res , context . functionName ); } catch ( err ) { // Add the error as metadata tracer . addErrorAsMetadata ( err as Error ); } // Close subsegment (the AWS Lambda one is closed automatically) handlerSegment . close (); return res ; } When using the captureLambdaHandler decorator or middleware, Tracer performs these additional tasks to ease operations: Handles the lifecycle of the subsegment Creates a ColdStart annotation to easily filter traces that have had an initialization overhead Captures any response, or full exceptions generated by the handler, and include as tracing metadata","title":"Lambda handler"},{"location":"core/tracer/#annotations-metadata","text":"Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions. Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional context for an operation using any native object. Annotations Metadata You can add annotations using putAnnotation method. 1 2 3 4 5 6 7 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = new Tracer ({ serviceName : 'my-service' }); export const handler = async ( _event : any , _context : any ) => { tracer . putAnnotation ( 'PaymentStatus' , \"SUCCESS\" ); } You can add metadata using putMetadata method. 1 2 3 4 5 6 7 8 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = new Tracer ({ serviceName : 'my-service' }); export const handler = async ( _event : any , _context : any ) => { const res = someLogic (); tracer . putMetadata ( 'PaymentResponse' , res ); }","title":"Annotations &amp; Metadata"},{"location":"core/tracer/#methods","text":"You can trace other methods using the captureMethod decorator or manual instrumentation. Info We currently support a middleware for tracing methods, let us know if you'd like to see one! Decorator Manual 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = Tracer (); class Lambda { @tracer . captureMethod () public getChargeId () : string { ... return 'foo bar' } public handler ( event : any , context : any ) { const chargeId = this . getChargeId (); const payment = collectPayment ( chargeId ); ... } } export const handlerClass = new Lambda (); export const getChargeId = handlerClass . getChargeId ; export const handler = handlerClass . handler ; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import { Tracer } from '@aws-lambda-powertools/tracer' ; import { Segment } from 'aws-xray-sdk-core' ; const tracer = new Tracer ({ serviceName : 'my-service' }); const chargeId = async () => { // Create subsegment & set it as active const subsegment = new Subsegment ( `### chargeId` ); tracer . setSegment ( subsegment ); let res ; try { res = await someLogic (); // Do something // Add the response as metadata tracer . putMetadata ( `chargeId response` , data ); } catch ( err ) { // Add the error as metadata subsegment . addError ( err , false ); } // Close subsegment subsegment . close (); return res ; } export const handler = async ( _event : any , _context : any ) => { const chargeId = this . getChargeId (); const payment = collectPayment ( chargeId ); ... }","title":"Methods"},{"location":"core/tracer/#advanced","text":"","title":"Advanced"},{"location":"core/tracer/#patching-aws-sdk-clients","text":"Tracer can patch AWS SDK clients and create traces when your application makes calls to AWS services. Info The following snippet assumes you are using AWS SDK v3 for JavaScript You can patch any AWS SDK clients by calling captureAWSv3Client method: index.ts 1 2 3 4 5 6 import { S3Client } from \"@aws-sdk/client-s3\" ; import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = new Tracer (); const client = new S3Client ({}); tracer . captureAWSv3Client ( client ); Info The following two snippets assume you are using AWS SDK v2 for JavaScript You can patch all AWS SDK clients by calling captureAWS method: index.ts 1 2 3 4 import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = new Tracer (); const AWS = tracer . captureAWS ( require ( 'aws-sdk' )); If you're looking to shave a few microseconds, or milliseconds depending on your function memory configuration, you can patch specific clients using captureAWSClient : index.ts 1 2 3 4 5 import { S3 } from \"aws-sdk\" ; import { Tracer } from '@aws-lambda-powertools/tracer' ; const tracer = new Tracer (); const s3 = tracer . captureAWSClient ( new S3 ({ apiVersion : \"2006-03-01\" }));","title":"Patching AWS SDK clients"},{"location":"core/tracer/#disabling-response-auto-capture","text":"Use POWERTOOLS_TRACER_CAPTURE_RESPONSE=false environment variable to instruct Tracer not to serialize function responses as metadata. This is commonly useful in three scenarios You might return sensitive information you don't want it to be added to your traces You might manipulate streaming objects that can be read only once ; this prevents subsequent calls from being empty You might return more than 64K of data e.g., message too long error","title":"Disabling response auto-capture"},{"location":"core/tracer/#disabling-exception-auto-capture","text":"Use POWERTOOLS_TRACER_CAPTURE_ERROR=false environment variable to instruct Tracer not to serialize exceptions as metadata. Commonly useful in one scenario You might return sensitive information from exceptions, stack traces you might not control","title":"Disabling exception auto-capture"},{"location":"core/tracer/#escape-hatch-mechanism","text":"You can use tracer.provider attribute to access all methods provided by the AWS X-Ray SDK . This is useful when you need a feature available in X-Ray that is not available in the Tracer utility, for example SQL queries tracing , or a custom logger . index.ts 1 2 3 4 5 6 import { Logger } from '@aws-lambda-powertools/logger' ; import { Tracer } from '@aws-lambda-powertools/tracer' ; const logger = new Logger (); const tracer = new Tracer () tracer . provider . setLogger ( logger )","title":"Escape hatch mechanism"},{"location":"core/tracer/#testing-your-code","text":"Tracer is disabled by default when not running in the AWS Lambda environment - This means no code changes or environment variables to be set.","title":"Testing your code"},{"location":"core/tracer/#tips","text":"Use annotations on key operations to slice and dice traces, create unique views, and create metrics from it via Trace Groups Use a namespace when adding metadata to group data more easily Annotations and metadata are added to the current subsegment opened. If you want them in a specific subsegment, create one via the escape hatch mechanism","title":"Tips"}]}